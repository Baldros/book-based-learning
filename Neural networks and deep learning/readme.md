# Neural Networks and Deep Learning ğŸ§ ğŸš€

> **"The Ultimate Primer from First Principles"** â€” A Modern Educational Classic.

Estudos baseados no aclamado livro online de **Michael Nielsen**. Este material Ã© mundialmente famoso por ser, possivelmente, a melhor introduÃ§Ã£o existente para quem quer entender a matemÃ¡tica e a lÃ³gica real por trÃ¡s das Redes Neurais, sem depender de "caixas pretas".

## âœ¨ O que torna este material especial?
Michael Nielsen foca na clareza absoluta. Ao invÃ©s de usar bibliotecas prontas logo de cara, ele guia o leitor na construÃ§Ã£o de uma rede neural **do zero** usando apenas Python e Numpy. Isso cria uma base mental indestrutÃ­vel sobre como o aprendizado realmente ocorre.

### ğŸ¯ Objetivos de Estudo
- **DesmistificaÃ§Ã£o**: Entender que redes neurais sÃ£o, essencialmente, algoritmos de otimizaÃ§Ã£o matemÃ¡tica elegantes.
- **Backpropagation**: Dominar o fluxo de erro que permite que as mÃ¡quinas aprendam.
- **DomÃ­nio de NumPy**: Praticar a manipulaÃ§Ã£o de tensores e matrizes de forma eficiente.

### ğŸ’ª Pontos Fortes da Abordagem
- **Pedagogia de Elite**: O autor antecipa as dÃºvidas do leitor e as resolve com analogias e visualizaÃ§Ãµes brilhantes.
- **Foco no "PorquÃª"**: Explica por que certas funÃ§Ãµes de ativaÃ§Ã£o funcionam melhor que outras e como evitar problemas comuns de treinamento.
- **Zero DependÃªncia**: NÃ£o Ã© sobre aprender uma ferramenta (como PyTorch ou TF), mas sobre aprender a *ciÃªncia*.

## ğŸ§  TÃ³picos Fundamentais
- **Perceptrons e NeurÃ´nios Sigmoides**: As unidades bÃ¡sicas de inteligÃªncia.
- **RetropropagaÃ§Ã£o (Backpropagation)**: O algoritmo que move o mundo da IA.
- **Overfitting e RegularizaÃ§Ã£o**: Como fazer o modelo generalizar para dados nunca vistos.
- **MNIST**: O "Hello World" da visÃ£o computacional (reconhecimento de dÃ­gitos).

## ğŸ“ ConteÃºdo do Estudo
- ImplementaÃ§Ã£o da rede neural manual.
- Notebooks de classificaÃ§Ã£o de dÃ­gitos manuscritos (MNIST).
- ExploraÃ§Ãµes sobre a convergÃªncia do aprendizado.
