{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f37b7001-5d71-4a14-b93b-83a66be70456",
   "metadata": {},
   "source": [
    "# Apresentação:\n",
    "\n",
    "O objetivo desse código é estudar sobre a preparação de textos com o [keras](https://keras.io/api/), uma API de aprendizado profundo escrita em Python e capaz de ser executada em [JAX](https://jax.readthedocs.io/en/latest/quickstart.html), [TensorFlow](https://www.tensorflow.org/?hl=pt-br) ou [PyTorch](https://pytorch.org/docs/stable/index.html), dado que, como já visto, não se alimenta modelos com *strings*, afinal, operações matemáticas é uma propriedade dos números. Dito isso, a ideia aqui é ver sobre:\n",
    "\n",
    "* Os métodos convenientes que pode-se usar para preparar rapidamente os dados de texto.\n",
    "* A API Tokenizer que pode ser ajustada nos dados de treinamento e usada para codificar documentos de treinamento, validação e teste.\n",
    "* A variedade de 4 diferentes esquemas de codificação de documentos oferecidos pela API Tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f24d4349-e78d-44b5-b9fe-31e3398b51a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c58c08-d679-47ad-a4af-98691da5a285",
   "metadata": {},
   "source": [
    "#  Splicando palavras com `text_to_word_sequence`\n",
    "\n",
    "Aqui continuamos com a ideia de tokenizar o texto em palavras, é uma forma arcaica de resolver essa questão, mas é útil no processo de estudo, por ser fácil de entender o processo. **Keras** fornece a função `text_to_word_sequence()` que você pode usar para dividir o texto em uma lista de palavras. Por padrão, esta função faz automaticamente três coisas:\n",
    "\n",
    "* Divide palavras por espaço;\n",
    "* Filtra pontuação;\n",
    "* Converte texto em *lowercase* `(lower=True)`\n",
    "\n",
    "A ideia aqui é que todo o processo de tratamento de *string* feita anteriormente é facilitada aqui. Deste modo, essa função do Keras facilita muito o trabalho. Dito isso, é importante dizer que todos os parâmetros apontados podem ser alterados para que função não faça tais mudanças."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5308e466-633f-43f9-8ed4-e3ce8fcc8d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando função:\n",
    "from keras.preprocessing.text import text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a206c68-f6cb-42a2-977c-5f54a7d7a597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'quick', 'brown', 'fox', 'jumped', 'over', 'the', 'lazy', 'dog'] 9\n"
     ]
    }
   ],
   "source": [
    "# Frase:\n",
    "text = 'The quick brown fox jumped over the lazy dog.'\n",
    "\n",
    "# Tokenização da frase:\n",
    "result = text_to_word_sequence(text)\n",
    "print(result, len(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4176fff5-1293-4d98-b789-7a94b205a5dc",
   "metadata": {},
   "source": [
    "#  Codificando com `one-hot`\n",
    "\n",
    "Como já dito, esse tipo de codificação é um método antigo de codificação, que gera matrizes muito esparças, todavia, a título de estudo codificar dessa forma. O Keras fornece a função `one_hot()`, que é diferente de bibliotecas como pandas, dado que aqui, não é simplemente zero ou um a saída, mas sim um **vetor números inteiro**. A função é um invólucro para a função `hashing_trick()`. A função retorna uma versão codificada em inteiros do documento. O uso de uma função de hash significa que **pode haver colisões** e **nem todas as palavras serão atribuídas a valores inteiros únicos**.\n",
    "\n",
    "Assim como a função `text_to_word_sequence()`, a função `one_hot()` converterá o texto para minúsculas, filtrará a pontuação e dividirá as palavras com base em espaços em branco.\n",
    "\n",
    "**Importante**\n",
    "\n",
    "Essa função foi descontinuada, de modo que a própria biblioteca não recomenda mais a sua utilização. Para mais informações, `help(one_hot)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f49a95b9-b83d-454a-bb56-1c7e1291b24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lazy', 'jumped', 'the', 'brown', 'quick', 'fox', 'dog', 'over'} 8\n"
     ]
    }
   ],
   "source": [
    "# Estimando o tamanho do vocabulário:\n",
    "words = set(text_to_word_sequence(text))\n",
    "vocab_size = len(words)\n",
    "print(words,vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98c5726a-2547-4aab-8f26-2f79f1eb5dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando a função one-hot\n",
    "from keras.preprocessing.text import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4501a69a-6c67-426f-8351-fcbd325a6c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 8, 5, 2, 3, 9, 3, 4, 9] 9\n"
     ]
    }
   ],
   "source": [
    "# Codificação com inteiros:\n",
    "resultEnconde = one_hot(text, round(vocab_size*1.3))\n",
    "print(resultEnconde,len(resultEnconde))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "02026a68-8591-43af-975f-05969c79b6d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Palavras</th>\n",
       "      <th>Codificação One_Hot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quick</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>brown</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fox</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jumped</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>over</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>the</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lazy</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dog</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Palavras  Codificação One_Hot\n",
       "0      the                    3\n",
       "1    quick                    8\n",
       "2    brown                    5\n",
       "3      fox                    2\n",
       "4   jumped                    3\n",
       "5     over                    9\n",
       "6      the                    3\n",
       "7     lazy                    4\n",
       "8      dog                    9"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizando Resposta:\n",
    "df = pd.concat([pd.DataFrame(result, columns=[\"Palavras\"]),\n",
    "                pd.DataFrame(resultEnconde,columns=[\"Codificação One_Hot\"])],axis=1) # Note que de fato há colisões\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa34bba-0b43-4eb3-8ab3-12e7cab3ee0f",
   "metadata": {},
   "source": [
    "# Hash Encoding with `hashing_trick`\n",
    "\n",
    "Uma limitação das codificações baseadas em inteiros e contagens é que elas precisam manter um vocabulário de palavras e seu mapeamento para inteiros. Uma alternativa a essa abordagem é usar uma função de **hash unidirecional** para converter palavras em inteiros. Isso evita a necessidade de acompanhar um vocabulário, o que é mais rápido e requer menos memória.\n",
    "\n",
    "O Keras fornece a funão `hashing_trik()` que tokeniza e, em seguida, codifica o documento em inteiros, assim como a função `one_hot()`. Ela oferece mais flexibilidade, permitindo que você especifique a função de hash como hash (o padrão) ou outras funções de hash, como a função `md5` embutida ou sua própria função."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a588393-3c06-48ec-84a4-8eeb4e7bd875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imporando a função de hash:\n",
    "from keras.preprocessing.text import hashing_trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b69d5f2-71ff-41c9-9645-14186b652729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lazy', 'jumped', 'the', 'brown', 'quick', 'fox', 'dog', 'over'} 8\n"
     ]
    }
   ],
   "source": [
    "# estimate the size of the vocabulary\n",
    "words = set(text_to_word_sequence(text))\n",
    "vocab_size = len(words)\n",
    "print(words,vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a069c3a-2f96-440c-9f54-4e3bb1898849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 4, 1, 2, 7, 5, 6, 2, 6] 9\n"
     ]
    }
   ],
   "source": [
    "# integer encode the document\n",
    "resultHashCodification = hashing_trick(text, round(vocab_size*1.3), hash_function='md5')\n",
    "print(result,len(resultHashCodification)) # Note que continua havendo colisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c755228e-0366-41ef-b35e-9da4d8b0b661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Palavras</th>\n",
       "      <th>Codificação One_Hot</th>\n",
       "      <th>Codificação Hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quick</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>brown</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fox</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jumped</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>over</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>the</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lazy</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dog</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Palavras  Codificação One_Hot  Codificação Hash\n",
       "0      the                    3                 6\n",
       "1    quick                    8                 4\n",
       "2    brown                    5                 1\n",
       "3      fox                    2                 2\n",
       "4   jumped                    3                 7\n",
       "5     over                    9                 5\n",
       "6      the                    3                 6\n",
       "7     lazy                    4                 2\n",
       "8      dog                    9                 6"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizando Resposta:\n",
    "df = pd.concat([df, pd.DataFrame(resultHashCodification,columns=[\"Codificação Hash\"])],axis=1) # Note que de fato há colisões\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7ff59200-0d0c-4512-89d6-ab35efb28e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Codificação One_Hot</th>\n",
       "      <th>Codificação Hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.111111</td>\n",
       "      <td>4.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.803767</td>\n",
       "      <td>2.179449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Codificação One_Hot  Codificação Hash\n",
       "mean             5.111111          4.333333\n",
       "std              2.803767          2.179449"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Avaliando estatísticas descritivas:\n",
    "df.describe().loc[\"mean\":\"std\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5440b52d-122c-4c52-9a04-0431d347422d",
   "metadata": {},
   "source": [
    "# Tokenizer API:\n",
    "\n",
    "O Keras fornece uma API mais sofisticada para preparar texto que pode ser ajustada e reutilizada para preparar vários documentos de texto. Esta pode ser a abordagem preferida para grandes projetos. O Keras fornece a classe `Tokenizer` para preparar documentos de texto para deep learning. O Tokenizer deve ser construído e, em seguida, ajustado em documentos de texto bruto ou documentos de texto codificados em inteiros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f9f87545-1a1e-47dd-a4b4-fb0a5fd0c991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando Classe Tokenizer:\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "09b8c9f0-7b74-4696-84f4-9b3b71ae99b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo 5 frases:\n",
    "docs = ['Well done!', 'Good work', 'Great effort', 'nice work', 'Excellent!']\n",
    "\n",
    "# Instanciando Tokenizer:\n",
    "t = Tokenizer()\n",
    "\n",
    "# Ajustando o tokenizer aos documentos\n",
    "t.fit_on_texts(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dbbd01-5e8d-4432-a365-8e0004b4f469",
   "metadata": {},
   "source": [
    "Uma vez ajustado, o `Tokenizer` fornece 4 atributos que podem ser usados para consultar o que foi\n",
    "aprendido sobre os documentos:\n",
    "\n",
    "* **contagem de palavras:** Um dicionário de palavras e suas contagens.\n",
    "* **word docs:** Uma contagem inteira do número total de documentos que foram usados ​​para ajustar o\n",
    "Tokenizador.\n",
    "* **índice de palavras:** Um dicionário de palavras e seus números inteiros atribuídos exclusivamente.\n",
    "* **contagem de documentos:** Um dicionário de palavras e em quantos documentos cada uma apareceu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fc40f0b5-07c9-45df-962e-1dad0cce3c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('well', 1), ('done', 1), ('good', 1), ('work', 2), ('great', 1), ('effort', 1), ('nice', 1), ('excellent', 1)]) \n",
      "\n",
      "5 \n",
      "\n",
      "{'work': 1, 'well': 2, 'done': 3, 'good': 4, 'great': 5, 'effort': 6, 'nice': 7, 'excellent': 8} \n",
      "\n",
      "defaultdict(<class 'int'>, {'done': 1, 'well': 1, 'good': 1, 'work': 2, 'effort': 1, 'great': 1, 'nice': 1, 'excellent': 1}) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sumário do que foi aprendido:\n",
    "print(t.word_counts, \"\\n\") # Nesse caso: Bigram, ou digram\n",
    "print(t.document_count, \"\\n\")\n",
    "print(t.word_index, \"\\n\")\n",
    "print(t.word_docs, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824335c9-9669-4d14-8c89-a4aad3100fb0",
   "metadata": {},
   "source": [
    "Uma vez que o `Tokenizer` foi ajustado nos dados de treinamento, ele pode ser usado para codificar documentos nos conjuntos de dados de treinamento ou teste. O método `texts_to_matrix()` do `Tokenizer` pode ser usado para criar um vetor por documento fornecido como entrada. O comprimento dos vetores é o tamanho total do vocabulário. Esta função fornece um conjunto de esquemas de codificação de texto do modelo **bag-of-words** que podem ser fornecidos através de um argumento de modo para a função. Os modos disponíveis incluem:\n",
    "\n",
    "* **binary:** Indica se cada palavra está presente no documento. Este é o padrão.\n",
    "* **count:** A contagem de cada palavra no documento.\n",
    "* **tfidf:** A pontuação de Frequência de Termo-Inversa Frequência de Documento **(TF-IDF)** para cada palavra no documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f5569cfa-1d49-4c64-a678-c69f1aa92b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# texto com codificação inteira\n",
    "encoded_docs = t.texts_to_matrix(docs, mode='count')\n",
    "print(encoded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a034382-5a44-41d3-87da-a9b0ac66906d",
   "metadata": {},
   "source": [
    "Esse é o nosso \"*One-hot-encoding*\" tradicional, deste modo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
